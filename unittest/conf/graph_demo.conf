name: "LRDemo"
node {
  name: "x"
  op: "Placeholder"
  device: "CPU"
}
node {
  name: "label"
  op: "Placeholder"
  device: "CPU"
}
node {
  name: "b"
  op: "Variable"
  device: "CPU"
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 1
          name: "rows"
        }
        dim {
          size: 10
          name: "cols"
        }
      }
    }
  }
  attr {
    key: "type"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "w"
  op: "Variable"
  device: "CPU"
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: 10
          name: "layer1"
        }
        dim {
          size: 8
          name: "layer0"
        }
      }
    }
  }
  attr {
    key: "type"
    value {
      type: DT_FLOAT
    }
  }
}
node {
  name: "z"
  op: "Add"
  input: "w*x"
  input: "b"
  device: "CPU"
  attr {
    key: "row_major"
    value {
      b: True
    }
  }
}
node {
  name: "reduce_sum_z"
  op: "ReduceSum"
  input: "z"
  device: "CPU"
  attr {
    key: "row_major"
    value {
      b: True
    }
  }
}
node {
  name: "y1"
  op: "sigmoid"
  input: "reduce_sum_z"
  device: "CPU"
  attr {
    key: "row_major"
    value {
      b: True
    }
  }
}
node {
  name: "y"
  op: "sigmoid"
  input: "y1"
  device: "CPU"
  attr {
    key: "row_major"
    value {
      b: True
    }
  }
  attr {
    key: "used_backward"
    value {
      b: False
    }
  }
}
node {
  name: "loss"
  op: "sigmoid_cross_entropy_with_logits"
  input: "label"
  input: "reduce_sum_z"
  device: "CPU"
  attr {
    key: "row_major"
    value {
      b: True
    }
  }
}
node {
  name: "w*x"
  op: "MatMul"
  input: "x"
  input: "w"
  device: "CPU"
  attr {
    key: "type"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "transpose_a"
    value {
      b: False
    }
  }
  attr {
    key: "transpose_b"
    value {
      b: True
    }
  }
}
version: 1
